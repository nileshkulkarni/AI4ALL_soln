{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2_Basic_Language_Processing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nileshkulkarni/AI4ALL_soln/blob/main/2_Basic_Language_Processing_soln.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egx0tQG4Z6qa"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/dangeng/AI4ALL_NLP/main/lib.py\n",
        "!mkdir data\n",
        "!wget -O data/cleaned_hm.csv https://raw.githubusercontent.com/megagonlabs/HappyDB/master/happydb/data/cleaned_hm.csv\n",
        "!wget -O data/demographic.csv https://raw.githubusercontent.com/megagonlabs/HappyDB/master/happydb/data/demographic.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4T3qjGEya3VH",
        "scrolled": false
      },
      "source": [
        "%matplotlib inline\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import lib\n",
        "import spacy\n",
        "import itertools\n",
        "from collections import Counter\n",
        "import statistics\n",
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvlBvxpxa3VK"
      },
      "source": [
        "# Basic Language Processing\n",
        "Now that we know a little bit about the demographics of the workers who helped to produce the dataset, let's start looking at the language! There are a few questions that we want to answer:\n",
        "* What makes people happy?\n",
        "* Do the things that cause happiness differ between groups?\n",
        "\n",
        "We'll start by using some simple techniques to answer the first question!\n",
        "\n",
        "First, we'll load the data. If you don't remember, look back at the first notebook to see how to load the joined data.\n",
        "\n",
        "Save it as `joined_data`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wy5w2f-Ma3VL",
        "scrolled": false
      },
      "source": [
        "# load the *joined* data!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgoYbxiy6i0c"
      },
      "source": [
        "## Getting Sentences\n",
        "First, go through `joined_data`, and create a list of happy moments. You will need to create a list of happy moments with various properties a few times, so make sure that you are very clear on how to do this using `joined_data`!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adG7gvPA6mL4"
      },
      "source": [
        "all_sentences = []\n",
        "# add the happy moment text for each happy moment to all_sentences\n",
        "# each happy moment is a dictionary\n",
        "# the happy moment text is stored in the property 'cleaned_hm'\n",
        "\n",
        "### YOUR WORK HERE!!!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJMdkiwQa3VQ"
      },
      "source": [
        "## Wordclouds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HM8LSExOa3VR"
      },
      "source": [
        "One way in which we can visualize text data is by using a word cloud. This will show us which words appear frequently in the text. Luckily, we don't need to write a bunch of code to display a word cloud - libraries exist to do it already! We have a function that can be used to create word clouds in the library, `lib.create_word_cloud`.\n",
        "\n",
        "Warning: The word cloud library is a bit slow, so if it takes a minute or two to load, don't worry - it probably doesn't have anything to do with your code!\n",
        "\n",
        "This is how you would call it on a list of sentences, `s`: `lib.create_word_cloud(s)`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0C8nkPza3VS",
        "scrolled": false
      },
      "source": [
        "# create your word cloud here\n",
        "### YOUR WORK HERE!!!\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbZh-PKaa3VU"
      },
      "source": [
        "Now let's do something a bit more interesting: later on, we will classify happiness posts by if they are made by a man or a woman. Let's create two word clouds: one of posts made by men, and one of posts made by women, and see how they differ. This will require two steps\n",
        "\n",
        "1. Separate out happy moments into entries written by women and entries written by men\n",
        "1. Create word clouds of each"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXFqNi3ma3VV",
        "scrolled": false
      },
      "source": [
        "man_sentences = []\n",
        "woman_sentences = []\n",
        "# complete the lists of sentences\n",
        "### YOUR WORK HERE!!!\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5EHBLy5a3VX",
        "scrolled": false
      },
      "source": [
        "# create the word cloud for women\n",
        "### YOUR WORK HERE!!!\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AdyJ72ja3VY",
        "scrolled": false
      },
      "source": [
        "# create the word cloud for men\n",
        "### YOUR WORK HERE!!!\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdIQhrUEa3Va"
      },
      "source": [
        "You probably notice a few differences between the word clouds - take a minute to jot some of them down."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CL3tzC2ta3Vb"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3O2Uaqea3Vc"
      },
      "source": [
        "Even though there are some differences, you'll probably notice that the word clouds look quite similar overall. Words that don't seem to meaningful like \"made happy\" and \"got\" are large in both word clouds.\n",
        "\n",
        "There are many ways that we can remove words that aren't meaningful. One typical approach is to use a \"stopwords\" list, which will include function words like \"the\", \"a\", \"an\", etc.\n",
        "\n",
        "The wordcloud library actually has a built-in list of stopwords, but we also should filter out some words that are common in happy moments even if they aren't common in written text overall."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzIkgoOp8V5Z"
      },
      "source": [
        "### Adding Domain-Specific Stopwords\n",
        "Try creating a domain-specific stopwords list, using words that you see frequently for _both_ men and women. Because these words are so common overall, they don't have much meaning for happy moments. There are two ways that you can do this; feel free to try both:\n",
        "\n",
        "1. Manually create a list\n",
        "1. Create a list of all words that appear in the top 100 for men _and_ women. Those words are likely very common overall. To do so, you'll need to figure out all of the words in the happy moments. This is a process called **tokenization**, which we will explore more later. For now, we've tokenized for you, creating the lists `man_tokens` and `woman_tokens` below.\n",
        "\n",
        "Something to you may notice is that the word cloud library uses n-grams (short phrases), not just individual words. It might be valuable to include multiple-word phrases like \"made happy\" in your stopwords list, even though it isn't really an individual word!\n",
        "\n",
        "You may also want to use a special function defined in `lib` to get the most common words in a list of words.\n",
        "\n",
        "It's usage is `lib.get_most_common_words(word_list, n)`, where `word_list` is a list of words, and `n` is the number of words to return.\n",
        "\n",
        "Here's an example of the usage:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wzmj3sSoUMl1"
      },
      "source": [
        "happy_words = ['happy', 'happy', 'family', 'happy', 'friends', 'work', 'friends']\n",
        "\n",
        "print(lib.get_most_common_words(happy_words, 2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYgUlWIUUMl1"
      },
      "source": [
        "If you want to make this more challenging, you can also write your own code to get the most common words from a list. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KArPFer_9wIm"
      },
      "source": [
        "def get_all_tokens(sentences):\n",
        "    tokens = []\n",
        "    for sentence in sentences:\n",
        "        tokens.extend(get_tokens(sentence))\n",
        "    return tokens\n",
        "\n",
        "def get_tokens(sentence):\n",
        "    tokens = []\n",
        "    for token in nltk.word_tokenize(sentence):\n",
        "        tokens.append(token.lower())\n",
        "    return tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBW6jq5M2a9P"
      },
      "source": [
        "man_tokens = get_all_tokens(man_sentences)\n",
        "woman_tokens = get_all_tokens(woman_sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_p7PcKuca3Vd",
        "scrolled": false
      },
      "source": [
        "# create your list of stopwords!\n",
        "### YOUR WORK HERE!!!\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DxNI9hna3Ve"
      },
      "source": [
        "After you have your personal stopwords list, pass it in to the word cloud function like this: `lib.create_word_cloud(sentences, stop=stop)` (it is an optional parameter)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iu06kb8ia3Vf",
        "scrolled": false
      },
      "source": [
        "# create the word cloud for women\n",
        "### YOUR WORK HERE!!!\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzPXlcn3a3Vh",
        "scrolled": false
      },
      "source": [
        "# create the word cloud for men\n",
        "### YOUR WORK HERE!!!\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQKX07Y2a3Vi"
      },
      "source": [
        "Hopefully, you now see more noticeable differences between the word clouds.\n",
        "\n",
        "Feel free to play around with the word clouds with different attributes, like age and country!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkUqg46ta3Vj"
      },
      "source": [
        "## Word Count\n",
        "Something else that might differ between men and women is the number of words included in what they write. Collect the overall average word count, in addition to average for men and average for women. What do you find?\n",
        "\n",
        "First, you'll need to count the tokens in each happy moment a) overall, b) for women, and c) for men. Create a list that has the number of tokens for each happy moment for each of the groups. To help you out, we've already done it for men. You will need to count for women and overall. You can use the same loop that we already started, or create a new loop!\n",
        "\n",
        "Then, you'll need to calculate the average values. To do this, you can call `statistics.mean` on the list. We'll have an example of how to do that below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0TTwJTOBTtv"
      },
      "source": [
        "overall_token_counts = []\n",
        "woman_token_counts = []\n",
        "man_token_counts = []\n",
        "\n",
        "# count tokens for each group\n",
        "# already written: men\n",
        "joined_data = lib.load_joined_data()\n",
        "for hm in joined_data:\n",
        "  if hm['gender'] == 'm':\n",
        "    happy_text = hm['cleaned_hm']\n",
        "    man_token_counts.append(len(get_tokens(happy_text)))\n",
        "\n",
        "### YOUR WORK HERE!!!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NgA0scMCukj"
      },
      "source": [
        "# This is how `statistics.mean` is used:\n",
        "numbers = [1, 2, 3, 4, 5]\n",
        "print(statistics.mean(numbers))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvBq09L5a3Vk",
        "scrolled": false
      },
      "source": [
        "# print out the means overall, for women, and for men\n",
        "### YOUR WORK HERE!!!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jx1ceWJa3Vm"
      },
      "source": [
        "Who tends to write more? What about parental status? Do parents write more or less than non-parents? Do the same thing that you just did for men and women: count tokens for each group, then calculate the average.\n",
        "\n",
        "You can use what you did for men and women as an example here, just look at the `'parenthood'` property instead of `'gender'`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7kpSlzzDGPe"
      },
      "source": [
        "parent_token_counts = []\n",
        "non_parent_token_counts = []\n",
        "\n",
        "# count up tokens\n",
        "### YOUR WORK HERE!!!\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWWxocrMa3Vm",
        "scrolled": false
      },
      "source": [
        "# print out the means for parents and non-parents\n",
        "### YOUR WORK HERE!!!\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcUbGJWRa3Vo"
      },
      "source": [
        "It seems as though parents write a bit more than non-parents! Why do you think that could be?\n",
        "\n",
        "Ultimately, word count does not tell us much about what makes different groups happy. However, it could be a useful tool when predicting who a happy moment description comes from. We will explore this more later. It does seem as though the word clouds, which represent which words are most frequently used when people talk about what makes them happy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOlI3F8Ua3Vq",
        "scrolled": false
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}